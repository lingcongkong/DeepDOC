{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447cba2a",
   "metadata": {},
   "source": [
    "## Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528d5b2",
   "metadata": {},
   "source": [
    "The experiment was repeated 1000 times for 5-fold cross validation\n",
    "\n",
    "Five machine learning algorithms are used: SVM, LR, RF, XGBoost, AdaBoost\n",
    "\n",
    "The performance evaluation indexes of the five models were calculated: acc, F1-score, precision, recall, auc, ap\n",
    "\n",
    "ROC curve and PR curve of the model were drawn for 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a14e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2844a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifty fold cross validation, 1000 repeats of the experiment\n",
    "def cv_repeat_model(cv, repeat, random_state, feature, y, model):\n",
    "    \n",
    "    cv_r = cv * repeat # cv-fold cross validation, repeat times\n",
    "    rkf = RepeatedKFold(n_splits=cv, n_repeats=repeat, random_state=100) # Repeat the cv-fold data partition repeat times\n",
    "    \n",
    "    x_train_r = []\n",
    "    x_test_r = []\n",
    "    y_train_label_r = []\n",
    "    y_test_label_r = []\n",
    "    for train_index_r,test_index_r in rkf.split(feature):\n",
    "        train_set_r = feature[train_index_r,:]\n",
    "        test_set_r = feature[test_index_r,:]\n",
    "        y_train = y[train_index_r]\n",
    "        y_test = y[test_index_r]\n",
    "        # Stack all five-fold results\n",
    "        x_train_r.append(train_set_r)\n",
    "        x_test_r.append(test_set_r)\n",
    "        y_train_label_r.append(y_train)\n",
    "        y_test_label_r.append(y_test)\n",
    "    \n",
    "    # training and predict\n",
    "    y_proba_label_r = []\n",
    "    for i in range(cv_r):\n",
    "        model.fit(x_train_r[i], y_train_label_r[i])   # model corresponds to five models respectively\n",
    "        y_proba_r = model.predict_proba(x_test_r[i])   \n",
    "        y_proba_r = np.array(list(y_proba_r[:, 1]))  \n",
    "        y_proba_label_r.append(y_proba_r)\n",
    "     \n",
    "    return cv_r, x_train_r, x_test_r, y_train_label_r, y_test_label_r, y_proba_label_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb2ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the probability and true classification of class 0\n",
    "def change_y(y_true, y_pred):\n",
    "    # Splice five folds\n",
    "    yy = np.concatenate(y_true).reshape(repeat, -1)  # Stack the 5 fold models for each training session\n",
    "    pp = np.concatenate(y_pred).reshape(repeat, -1)\n",
    "    \n",
    "    y_true_r = []\n",
    "    y_pred_r = []\n",
    "    for i in range(len(repeat)):\n",
    "        y_true_k = pd.DataFrame(yy[i]).rename(columns={0:'y_1'})\n",
    "        y_pred_k = pd.DataFrame(pp[i]).rename(columns={0:'pred_1'})\n",
    "        y = pd.concat([y_true_k, y_pred_k], axis=1)\n",
    "\n",
    "        y['pred_0'] = \"\"\n",
    "        y['y_0'] = \"\"\n",
    "        y_true_i, y_pred_i = y_0_1(y)\n",
    "        y_true_r.append(y_true_i)\n",
    "        y_pred_r.append(y_pred_i)\n",
    "        \n",
    "    return y_true_r, y_pred_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600ce2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "def plot_roc_curve(y_true_r, y_pred_r, text_list, path):\n",
    "    # Calculate ROC curve parameters\n",
    "    mean_fpr_micro = np.linspace(0, 1, 100)\n",
    "    fprs_micro = []\n",
    "    tprs_micro = []\n",
    "    auc_micro = []\n",
    "    for k in range(len(y_true_r)):\n",
    "        # Calculate the parameters required for the curve\n",
    "        fpr, tpr, thres = roc_curve(y_true_r[k].ravel(), y_pred_r[k].ravel()) \n",
    "       \n",
    "        fprs_micro.append(fpr)\n",
    "        \n",
    "        interp_tpr = np.interp(mean_fpr_micro, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs_micro.append(interp_tpr)\n",
    "        \n",
    "    mean_tpr_micro = np.mean(tprs_micro, axis=0)\n",
    "    mean_tpr_micro[-1] = 1.0\n",
    "    std_tpr_micro = np.std(tprs_micro, axis=0)\n",
    "    \n",
    "    # Minimum and maximum values of 1000 repetitions, upper and lower limits of the interval of the ROC curve\n",
    "    tprs_lower_micro = np.maximum(mean_tpr_micro - std_tpr_micro, 0)\n",
    "    tprs_upper_micro = np.minimum(mean_tpr_micro + std_tpr_micro, 1)\n",
    "    \n",
    "    for k in range(len(y_true_r)):\n",
    "        micro = roc_auc_score(y_true_r[k], y_pred_r[k], average='micro', multi_class='ovr')\n",
    "        auc_micro.append(micro)\n",
    "    \n",
    "    auc_mean_micro = np.mean(auc_micro)\n",
    "    auc_std_micro = np.std(auc_micro)\n",
    "    \n",
    "    # Draw ROC curve\n",
    "    size = 20\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='grey', alpha=.8)\n",
    "    \n",
    "    plt.plot(mean_fpr_micro, mean_tpr_micro, color='#2878B5',label=r'AUC = %0.3f $\\pm$ %0.3f' % (auc_mean_micro, auc_std_micro),lw=2, alpha=1)\n",
    "    plt.fill_between(mean_fpr_micro, tprs_lower_micro, tprs_upper_micro, color='#82B0D2', alpha=.6, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set(xlim=[-0.02, 1.02], ylim=[-0.02, 1.02])\n",
    "    plt.legend(loc=\"lower right\",fontsize=size-2)\n",
    "    plt.title(text_list,weight='bold', fontdict={'size':size})\n",
    "    plt.ylabel('True positive rate',weight='bold', fontdict={'size':size-2})\n",
    "    plt.xlabel('False positive rate',weight='bold', fontdict={'size':size-2})\n",
    "    \n",
    "    plt.savefig(path, transparent=False, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0c1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(y_true_r, y_pred_r, text_list, save_path):\n",
    "    # Calculate PR curve parameters\n",
    "    size=18\n",
    "    mean_rc = np.linspace(0, 1, 100)\n",
    "    prs = []\n",
    "    aucs = []\n",
    "    for k in range(len(y_true_r)):\n",
    "        # Calculate the parameters required for the curve\n",
    "        pr, rc, thres = precision_recall_curve(y_true_r[k][:,1], y_pred_r[k][:,1], pos_label=1)\n",
    "        pr, rc = pr[::-1], rc[::-1]\n",
    "        interp_pr = np.interp(mean_rc, rc, pr)\n",
    "        interp_pr[0] = 1.0 \n",
    "        prs.append(interp_pr)\n",
    "        \n",
    "        AUC = average_precision_score(y_true_r[k][:,1], y_pred_r[k][:,1], pos_label=1)\n",
    "        aucs.append(AUC)\n",
    "        \n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    mean_pr = np.mean(prs, axis=0)\n",
    "    std_pr = np.std(prs, axis=0)\n",
    "    \n",
    "    # Minimum and maximum values of 1000 repetitions, upper and lower limits of the interval of the PR curve\n",
    "    prs_upper = np.minimum(mean_pr + std_pr, 1)\n",
    "    prs_lower = np.maximum(mean_pr - std_pr, 0)\n",
    "\n",
    "    \n",
    "    # Draw PR curve\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(mean_rc, mean_pr, color='#FFA500',label='%s (AP=%0.3f $\\pm$ %0.3f)' % (model, mean_auc, std_auc),lw=2, alpha=1)\n",
    "    plt.fill_between(mean_rc, prs_lower, prs_upper, color='#FFD700', alpha=.6, label=r'$\\pm$ 1 std. dev.')\n",
    "    plt.plot([0, 1], [np.min(mean_pr), np.min(mean_pr)], linestyle='--', label=r'Baseline (AP=%0.3f)' % (np.min(mean_pr)), lw=2, color='grey', alpha=.8)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set(xlim=[-0.02, 1.02], ylim=[-0.02, 1.02])\n",
    "    plt.legend(loc=\"lower right\",fontsize=size-2)\n",
    "    plt.title(text_list,weight='bold', fontdict={'size':size})\n",
    "    plt.ylabel('Precision',weight='bold', fontdict={'size':size-2})\n",
    "    plt.xlabel('Recall',weight='bold', fontdict={'size':size-2})\n",
    "    \n",
    "    plt.savefig(save_path, transparent=False, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f03e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model performance evaluation index\n",
    "def report(y_true, y_pred):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    acc = []\n",
    "    auc = []\n",
    "    ap = []\n",
    "    for i in range(len(y_true)):\n",
    "        result = pd.DataFrame(classification_report(y_true[i][:,1], y_pred[i][:,1]>0.5, output_dict=True))\n",
    "        precision.append(result['weighted avg']['precision'])\n",
    "        recall.append(result['weighted avg']['recall'])\n",
    "        f1.append(result['weighted avg']['f1-score'])\n",
    "        acc.append(result['accuracy']['support'])\n",
    "        auc.append(roc_auc_score(y_true[i], y_pred[i], average='micro', multi_class='ovr'))\n",
    "        ap.append(average_precision_score(y_true[i][:,1], y_pred[i][:,1], pos_label=1))\n",
    "    \n",
    "    # The mean value, standard deviation and 95% confidence interval of seven evaluation indexes were calculated respectively\n",
    "    print('auc:{0}, {1}, {2}'.format(np.mean(auc), np.std(auc), np.percentile(auc, (2.5, 97.5))))\n",
    "    print('ap:{0}, {1}, {2}'.format(np.mean(ap), np.std(ap), np.percentile(ap, (2.5, 97.5))))\n",
    "    print('recall:{0}, {1}, {2}'.format(np.mean(recall), np.std(recall), np.percentile(recall, (2.5, 97.5))))\n",
    "    print('precision:{0}, {1}, {2}'.format(np.mean(precision), np.std(precision), np.percentile(precision, (2.5, 97.5))))\n",
    "    print('f1:{0}, {1}, {2}'.format(np.mean(f1), np.std(f1), np.percentile(f1, (2.5, 97.5))))\n",
    "    print('acc:{0}, {1}, {2}'.format(np.mean(acc), np.std(acc), np.percentile(acc, (2.5, 97.5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db3684",
   "metadata": {},
   "source": [
    "## The two-stage classification tasks are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe5f63",
   "metadata": {},
   "source": [
    "#### HC vs DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7088f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "feature_table = pd.read_csv('./data/fc_feature.csv')\n",
    "feature = np.array(feature_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22aa10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "y = np.array(pd.read_csv('./data/y_label.csv')['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb52c17",
   "metadata": {},
   "source": [
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b80c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', random_state=0, probability=True)\n",
    "cv_svc, x_train_svc, x_test_svc, y_train_label_svc, y_test_label_svc, y_proba_label_svc = cv_repeat_model(5, 1000, 100, feature, y, svc)\n",
    "y_true_svc, y_pred_svc = change_y(y_test_label_svc, y_proba_label_svc)\n",
    "plot_roc_curve(y_test_label_svc, y_proba_label_svc, 'SVM', './SVM_doc_control.tif')\n",
    "plot_pr_curve(y_test_label_svc, y_proba_label_svc, 'SVM', './SVM_doc_control.tif')\n",
    "report(y_test_label_svc, y_proba_label_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e45786",
   "metadata": {},
   "source": [
    "2. LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "cv_lr, x_train_lr, x_test_lr, y_train_label_lr, y_test_label_lr, y_proba_label_lr = cv_repeat_model(5, 1000, 100, feature, y, lr)\n",
    "y_true_lr, y_pred_lr = change_y(y_test_label_lr, y_proba_label_lr)\n",
    "plot_roc_curve(y_test_label_lr, y_proba_label_lr, 'LR', './LR_doc_control.tif')\n",
    "plot_pr_curve(y_test_label_svc, y_proba_label_svc, 'LR', './LR_doc_control.tif')\n",
    "report(y_test_label_lr, y_proba_label_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53119fb5",
   "metadata": {},
   "source": [
    "3. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665cc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "cv_rf, x_train_rf, x_test_rf, y_train_label_rf, y_test_label_rf, y_proba_label_rf = cv_repeat_model(5, 1000, 100, feature, y, rf)\n",
    "y_true_rf, y_pred_rf = change_y(y_test_label_rf, y_proba_label_rf)\n",
    "plot_roc_curve(y_test_label_rf, y_proba_label_rf, 'RF', './RF_doc_control.tif')\n",
    "plot_pr_curve(y_test_label_rf, y_proba_label_rf, 'RF', './RF_doc_control.tif')\n",
    "report(y_test_label_rf, y_proba_label_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0df703a",
   "metadata": {},
   "source": [
    "4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a659c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier(n_estimators=1000, random_state=0, eval_metric='mlogloss', use_label_encoder=False)\n",
    "cv_xg, x_train_xg, x_test_xg, y_train_label_xg, y_test_label_xg, y_proba_label_xg = cv_repeat_model(5, 1000, 100, feature, y, xg)\n",
    "y_true_xg, y_pred_xg = change_y(y_test_label_xg, y_proba_label_xg)\n",
    "plot_roc_curve(y_test_label_xg, y_proba_label_xg, 'XGBoost', './XGBoost_doc_control.tif')\n",
    "plot_pr_curve(y_test_label_xg, y_proba_label_xg, 'XGBoost', './XGBoost_doc_control.tif')\n",
    "report(y_test_label_xg, y_proba_label_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c74d44",
   "metadata": {},
   "source": [
    "5. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c68cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "cv_ada, x_train_ada, x_test_ada, y_train_label_ada, y_test_label_ada, y_proba_label_ada = cv_repeat_model(5, 1000, 100, feature, y, ada)\n",
    "y_true_ada, y_pred_ada = change_y(y_test_label_ada, y_proba_label_ada)\n",
    "plot_roc_curve(y_test_label_ada, y_proba_label_ada, 'AdaBoost', './AdaBoost_doc_control.tif')\n",
    "plot_pr_curve(y_test_label_ada, y_proba_label_ada, 'AdaBoost', './AdaBoost_doc_control.tif')\n",
    "report(y_test_label_ada, y_proba_label_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c6865",
   "metadata": {},
   "source": [
    "#### MCS vs UWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2 = feature[:51, :]\n",
    "y_2 = y[:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d53eb48",
   "metadata": {},
   "source": [
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb245022",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_2 = SVC(kernel='linear', random_state=0, probability=True)\n",
    "cv_svc_2, x_train_svc_2, x_test_svc_2, y_train_label_svc_2, y_test_label_svc_2, y_proba_label_svc_2 = cv_repeat_model(5, 1000, 100, feature_2, y_2, svc_2)\n",
    "y_true_svc_2, y_pred_svc_2 = change_y(y_test_label_svc_2, y_proba_label_svc_2)\n",
    "plot_roc_curve(y_test_label_svc_2, y_proba_label_svc_2, 'SVM', './SVM_mcs_vs.tif')\n",
    "plot_pr_curve(y_test_label_svc_2, y_proba_label_svc_2, 'SVM', './SVM_mcs_vs.tif')\n",
    "report(y_test_label_svc_2, y_proba_label_svc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ebeef",
   "metadata": {},
   "source": [
    "2. LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a78ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_2 = LogisticRegression(random_state=0)\n",
    "cv_lr_2, x_train_lr_2, x_test_lr_2, y_train_label_lr_2, y_test_label_lr_2, y_proba_label_lr_2 = cv_repeat_model(5, 1000, 100, feature_2, y_2, lr_2)\n",
    "y_true_lr_2, y_pred_lr_2 = change_y(y_test_label_lr_2, y_proba_label_lr_2)\n",
    "plot_roc_curve(y_test_label_lr_2, y_proba_label_lr_2, 'LR', './LR_mcs_vs.tif')\n",
    "plot_pr_curve(y_test_label_svc_2, y_proba_label_svc_2, 'LR', './LR_mcs_vs.tif')\n",
    "report(y_test_label_lr_2, y_proba_label_lr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89c64d",
   "metadata": {},
   "source": [
    "3. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf901bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "cv_rf_2, x_train_rf_2, x_test_rf_2, y_train_label_rf_2, y_test_label_rf_2, y_proba_label_rf_2 = cv_repeat_model(5, 1000, 100, feature_2, y_2, rf_2)\n",
    "y_true_rf_2, y_pred_rf_2 = change_y(y_test_label_rf_2, y_proba_label_rf_2)\n",
    "plot_roc_curve(y_test_label_rf_2, y_proba_label_rf_2, 'RF', './RF_mcs_vs.tif')\n",
    "plot_pr_curve(y_test_label_rf_2, y_proba_label_rf_2, 'RF', './RF_mcs_vs.tif')\n",
    "report(y_test_label_rf_2, y_proba_label_rf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2dba28",
   "metadata": {},
   "source": [
    "4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_2 = XGBClassifier(n_estimators=1000, random_state=0, eval_metric='mlogloss', use_label_encoder=False)\n",
    "cv_xg_2, x_train_xg_2, x_test_xg_2, y_train_label_xg_2, y_test_label_xg_2, y_proba_label_xg_2 = cv_repeat_model(5, 1000, 100, feature_2, y_2, xg_2)\n",
    "y_true_xg_2, y_pred_xg_2 = change_y(y_test_label_xg_2, y_proba_label_xg_2)\n",
    "plot_roc_curve(y_test_label_xg_2, y_proba_label_xg_2, 'XGBoost', './XGBoost_mcs_vs.tif')\n",
    "plot_pr_curve(y_test_label_xg_2, y_proba_label_xg_2, 'XGBoost', './XGBoost_mcs_vs.tif')\n",
    "report(y_test_label_xg_2, y_proba_label_xg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d5f01",
   "metadata": {},
   "source": [
    "5. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_2 = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "cv_ada_2, x_train_ada_2, x_test_ada_2, y_train_label_ada_2, y_test_label_ada_2, y_proba_label_ada_2 = cv_repeat_model(5, 1000, 100, feature_2, y_2, ada_2)\n",
    "y_true_ada_2, y_pred_ada_2 = change_y(y_test_label_ada_2, y_proba_label_ada_2)\n",
    "plot_roc_curve(y_test_label_ada_2, y_proba_label_ada_2, 'AdaBoost', './AdaBoost_mcs_vs.tif')\n",
    "plot_pr_curve(y_test_label_ada_2, y_proba_label_ada_2, 'AdaBoost', './AdaBoost_mcs_vs.tif')\n",
    "report(y_test_label_ada_2, y_proba_label_ada_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
